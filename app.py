import streamlit as st
import io
import os
import re
import base64
import pandas as pd
from collections import Counter
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords

# åˆå§‹åŒ–NLTKèµ„æºï¼ˆé¦–æ¬¡è¿è¡Œæ—¶ä¸‹è½½ï¼‰
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# å®‰è£…å¹¶å¯¼å…¥å¿…è¦çš„PDFå¤„ç†åº“
import sys
try:
    import PyPDF2
except ImportError:
    os.system(f"{sys.executable} -m pip install PyPDF2==3.0.1")
    import PyPDF2

try:
    import pdfplumber
except ImportError:
    os.system(f"{sys.executable} -m pip install pdfplumber")
    import pdfplumber

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="PDFå¤šåŠŸèƒ½å·¥å…·",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #0D47A1;
    }
    .knowledge-point {
        background-color: #f8f9fa;
        border-left: 4px solid #4CAF50;
        padding: 10px;
        margin: 10px 0;
        border-radius: 4px;
    }
    .highlight {
        background-color: #fff3cd;
        font-weight: bold;
    }
    .debug-info {
        background-color: #f1f1f1;
        padding: 10px;
        border-radius: 4px;
        font-family: monospace;
        font-size: 0.8rem;
        max-height: 200px;
        overflow-y: auto;
    }
    .error-message {
        color: #d32f2f;
        background-color: #ffebee;
        padding: 10px;
        border-radius: 4px;
        margin: 10px 0;
    }
    .warning-message {
        color: #ff6f00;
        background-color: #fff8e1;
        padding: 10px;
        border-radius: 4px;
        margin: 10px 0;
    }
    .feature-option {
        padding: 10px;
        border-radius: 5px;
        background-color: #f5f5f5;
        margin: 5px 0;
        cursor: pointer;
    }
    .feature-option:hover {
        background-color: #e0e0e0;
    }
</style>
""", unsafe_allow_html=True)

def extract_text_from_pdf(pdf_file, debug=False):
    """ä»PDFæ–‡ä»¶æå–æ–‡æœ¬ï¼Œæ”¯æŒå¤šç§æ–¹æ³•"""
    results = {}
    errors = []
    text = ""
    
    # æ–¹æ³•1: ä½¿ç”¨PyPDF2
    try:
        pdf_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        reader = PyPDF2.PdfReader(pdf_file)
        pypdf2_text = ""
        for page in reader.pages:
            page_text = page.extract_text() or ""
            pypdf2_text += page_text + "\n\n"
        
        if pypdf2_text.strip():
            text = pypdf2_text
            results['PyPDF2'] = pypdf2_text
        else:
            errors.append("PyPDF2æœªèƒ½æå–ä»»ä½•æ–‡æœ¬")
    except Exception as e:
        errors.append(f"PyPDF2é”™è¯¯: {str(e)}")
    
    # æ–¹æ³•2: ä½¿ç”¨pdfplumber
    if not text.strip():
        try:
            pdf_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
            with pdfplumber.open(pdf_file) as pdf:
                plumber_text = ""
                for page in pdf.pages:
                    page_text = page.extract_text() or ""
                    plumber_text += page_text + "\n\n"
                
                if plumber_text.strip():
                    text = plumber_text
                    results['pdfplumber'] = plumber_text
                else:
                    errors.append("pdfplumberæœªèƒ½æå–ä»»ä½•æ–‡æœ¬")
        except Exception as e:
            errors.append(f"pdfplumberé”™è¯¯: {str(e)}")
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
    if not text.strip():
        text = "æ— æ³•æå–æ–‡æœ¬ã€‚è¿™å¯èƒ½æ˜¯æ‰«æç‰ˆPDFæ²¡æœ‰æ–‡æœ¬å±‚ï¼Œæˆ–æ–‡ä»¶å—åˆ°ä¿æŠ¤ã€‚"
    
    # å¤„ç†ä¸€äº›å¸¸è§çš„PDFæå–é—®é¢˜
    if text.strip():
        # åˆ é™¤é‡å¤çš„è¡Œ
        lines = text.splitlines()
        cleaned_lines = []
        prev_line = ""
        for line in lines:
            if line != prev_line:
                cleaned_lines.append(line)
            prev_line = line
        text = "\n".join(cleaned_lines)
        
        # æ›¿æ¢ä¸€äº›å¸¸è§çš„ä¹±ç å­—ç¬¦
        text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\xff]', '', text)
        
        # å¦‚æœæå–çš„æ–‡æœ¬æ˜¯URLæˆ–æ˜æ˜¾çš„ä¹±ç æ¨¡å¼ï¼Œç»™å‡ºè­¦å‘Š
        if re.search(r'(https?:\/\/[^\s]+){3,}', text):
            errors.append("è­¦å‘Š: æå–çš„æ–‡æœ¬å¯èƒ½åŒ…å«å¤§é‡URLæˆ–ä¹±ç ï¼Œè¿™å¯èƒ½æ˜¯PDFæ ¼å¼é—®é¢˜")
    
    if debug:
        return text, results, errors
    return text

def preprocess_text(text):
    """é¢„å¤„ç†æ–‡æœ¬"""
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œå¤šä½™ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^\w\s\.\,\;\:\?\!ï¼Œã€‚ï¼›ï¼šï¼Ÿï¼ã€]', '', text)
    return text

def extract_sentences(text, min_length=5):
    """æå–æ–‡æœ¬ä¸­çš„å¥å­"""
    # å¤„ç†ä¸­æ–‡å’Œè‹±æ–‡æ··åˆå¥å­
    text = re.sub(r'([ã€‚ï¼ï¼Ÿï¼›!?;])', r'\1\n', text)
    sentences = []
    for line in text.split('\n'):
        if line.strip():
            # å¯¹äºè‹±æ–‡å’Œæ··åˆæ–‡æœ¬ä½¿ç”¨NLTK
            sentences.extend(sent_tokenize(line))
    
    # è¿‡æ»¤å¤ªçŸ­çš„å¥å­
    return [s.strip() for s in sentences if len(s.strip().split()) >= min_length or len(s.strip()) >= 10]

def score_importance(sentence, keywords=None, stop_words=None, language='auto'):
    """è¯„ä¼°å¥å­çš„é‡è¦æ€§"""
    if language == 'auto':
        # ç®€å•æ£€æµ‹è¯­è¨€
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', sentence))
        if chinese_chars > len(sentence) / 3:
            language = 'chinese'
        else:
            language = 'english'
    
    if stop_words is None:
        try:
            if language == 'chinese':
                # ä¸­æ–‡åœç”¨è¯
                stop_words = set([
                    'çš„', 'äº†', 'å’Œ', 'æ˜¯', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'ä¸', 'è¿™', 'é‚£', 'æœ‰', 'åœ¨',
                    'ä¸­', 'ä¸º', 'å¯¹', 'ä¹Ÿ', 'ä»¥', 'äº', 'ä¸Š', 'ä¸‹', 'ä¹‹', 'ç”±', 'ç­‰', 'è¢«'
                ])
            else:
                stop_words = set(stopwords.words('english'))
        except:
            stop_words = set()
    
    # æ ¹æ®è¯­è¨€é€‰æ‹©åˆ†è¯æ–¹æ³•
    if language == 'chinese':
        # ç®€å•ä¸­æ–‡åˆ†è¯ï¼ˆå­—ç¬¦çº§ï¼‰
        words = list(sentence)
    else:
        words = word_tokenize(sentence.lower())
    
    # è¿‡æ»¤åœç”¨è¯
    filtered_words = [w for w in words if w not in stop_words and (w.isalnum() or re.match(r'[\u4e00-\u9fff]', w))]
    
    # åŸºæœ¬åˆ†æ•°è®¡ç®—
    score = 0.5  # åŸºç¡€åˆ†æ•°
    
    # å¥å­é•¿åº¦å› ç´ 
    length = len(filtered_words)
    if length > 20:
        score += 0.1
    elif length > 10:
        score += 0.05
    
    # å…³é”®è¯åŒ¹é…
    if keywords:
        matches = sum(1 for word in filtered_words if word in keywords)
        score += 0.05 * matches
    
    # åŒ…å«æ•°å­—é€šå¸¸è¡¨ç¤ºæ›´å…·ä½“çš„ä¿¡æ¯
    if any(c.isdigit() for c in sentence):
        score += 0.05
    
    # ç‰¹æ®Šæ ‡è®°è¯è¯­ï¼Œé€šå¸¸è¡¨ç¤ºé‡è¦å†…å®¹
    importance_markers = {
        'english': ["important", "key", "significant", "essential", "crucial", "critical", "note", "remember"],
        'chinese': ["é‡è¦", "å…³é”®", "æ˜¾è‘—", "æœ¬è´¨", "è‡³å…³é‡è¦", "å…³é”®", "æ³¨æ„", "è®°ä½", "æ ¸å¿ƒ", "ä¸»è¦"]
    }
    
    markers = importance_markers.get(language, [])
    if any(marker in (words if language == 'chinese' else [w.lower() for w in words]) for marker in markers):
        score += 0.1
    
    return min(score, 1.0)  # ç¡®ä¿åˆ†æ•°ä¸è¶…è¿‡1.0

def extract_keywords(text, top_n=20, language='auto'):
    """æå–æ–‡æœ¬ä¸­çš„å…³é”®è¯"""
    if language == 'auto':
        # ç®€å•æ£€æµ‹è¯­è¨€
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        if chinese_chars > len(text) / 3:
            language = 'chinese'
        else:
            language = 'english'
    
    try:
        if language == 'chinese':
            # ç®€å•çš„ä¸­æ–‡å…³é”®è¯æå–ï¼ˆæŒ‰å­—ç¬¦é¢‘ç‡ï¼‰
            words = list(text)
            stop_words = set([
                'çš„', 'äº†', 'å’Œ', 'æ˜¯', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'ä¸', 'è¿™', 'é‚£', 'æœ‰', 'åœ¨',
                'ä¸­', 'ä¸º', 'å¯¹', 'ä¹Ÿ', 'ä»¥', 'äº', 'ä¸Š', 'ä¸‹', 'ä¹‹', 'ç”±', 'ç­‰', 'è¢«'
            ])
        else:
            # è‹±æ–‡å…³é”®è¯æå–
            stop_words = set(stopwords.words('english'))
            words = word_tokenize(text.lower())
            
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        filtered_words = [w for w in words if w not in stop_words and ((len(w) > 1 and language == 'chinese') or (len(w) > 2 and language != 'chinese'))]
        
        # ç»Ÿè®¡è¯é¢‘
        word_counts = Counter(filtered_words)
        
        # è¿”å›æœ€å¸¸è§çš„è¯
        return [word for word, _ in word_counts.most_common(top_n)]
    except Exception as e:
        st.warning(f"æå–å…³é”®è¯æ—¶å‡ºé”™: {str(e)}ï¼Œå°†ä½¿ç”¨ç®€åŒ–æ–¹æ³•")
        # ç®€åŒ–æ–¹æ³•ï¼šæŒ‰è¯é¢‘æå–
        words = text.split() if language != 'chinese' else list(text)
        word_counts = Counter(words)
        return [word for word, _ in word_counts.most_common(top_n)]

def get_chapter_headings(text):
    """å°è¯•æå–ç« èŠ‚æ ‡é¢˜"""
    # åŒ¹é…å¸¸è§çš„ç« èŠ‚æ ‡é¢˜æ¨¡å¼
    patterns = [
        # è‹±æ–‡æ¨¡å¼
        r'(?:Chapter|CHAPTER)\s+\d+[:\.\s]+(.+?)(?:\n|\r\n?)',
        r'(?:Section|SECTION)\s+\d+(?:\.\d+)*[:\.\s]+(.+?)(?:\n|\r\n?)',
        r'^\d+(?:\.\d+)*[:\.\s]+(.+?)(?:\n|\r\n?)',
        # ä¸­æ–‡æ¨¡å¼
        r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+\s*[ç« èŠ‚]\s*[ï¼š:]\s*(.+?)(?:\n|\r\n?)',
        r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[\.ã€]\s*(.+?)(?:\n|\r\n?)',
        r'[ï¼ˆ\(][ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ï¼‰\)]\s*(.+?)(?:\n|\r\n?)'
    ]
    
    headings = []
    for pattern in patterns:
        matches = re.findall(pattern, text, re.MULTILINE)
        headings.extend(matches)
    
    # å»é‡å¹¶æŒ‰åŸå§‹é¡ºåºä¿ç•™
    seen = set()
    unique_headings = []
    for h in headings:
        h_stripped = h.strip()
        if h_stripped and h_stripped not in seen and len(h_stripped) < 100:  # é¿å…åŒ¹é…è¿‡é•¿çš„å†…å®¹
            seen.add(h_stripped)
            unique_headings.append(h_stripped)
    
    return unique_headings

def create_downloadable_link(content, filename, link_text):
    """åˆ›å»ºå¯ä¸‹è½½å†…å®¹çš„é“¾æ¥"""
    b64 = base64.b64encode(content.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="{filename}" class="btn btn-primary">{link_text}</a>'
    return href

def extract_knowledge_points(text, mode, importance_threshold):
    """æ ¹æ®ä¸åŒæ¨¡å¼æå–çŸ¥è¯†ç‚¹"""
    text = preprocess_text(text)
    
    # æ£€æµ‹è¯­è¨€
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    language = 'chinese' if chinese_chars > len(text) / 10 else 'english'
    
    if mode == "è‡ªåŠ¨æ¨¡å¼":
        # æ£€æµ‹æ–‡æ¡£ç»“æ„ï¼Œé€‰æ‹©é€‚åˆçš„æ¨¡å¼
        headings = get_chapter_headings(text)
        if len(headings) > 2:
            mode = "ç« èŠ‚æ¨¡å¼"
        else:
            mode = "å¥å­æ¨¡å¼"
    
    # æå–å…³é”®è¯
    keywords = extract_keywords(text, language=language)
    
    if mode == "å…³é”®è¯æ¨¡å¼":
        # ç›´æ¥è¿”å›å…³é”®è¯ä½œä¸ºçŸ¥è¯†ç‚¹
        return [{"text": kw, "importance": 0.7, "type": "keyword"} for kw in keywords if kw]
    
    elif mode == "å¥å­æ¨¡å¼":
        # æå–å’Œè¯„åˆ†å¥å­
        sentences = extract_sentences(text)
        knowledge_points = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            importance = score_importance(sentence, keywords, language=language)
            if importance >= importance_threshold:
                knowledge_points.append({
                    "text": sentence,
                    "importance": importance,
                    "type": "sentence"
                })
        
        # æŒ‰é‡è¦æ€§é™åºæ’åº
        return sorted(knowledge_points, key=lambda x: x["importance"], reverse=True)
    
    elif mode == "ç« èŠ‚æ¨¡å¼":
        # æå–ç« èŠ‚æ ‡é¢˜å’Œç›¸å…³å†…å®¹
        headings = get_chapter_headings(text)
        
        if not headings:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç« èŠ‚æ ‡é¢˜ï¼Œå›é€€åˆ°å¥å­æ¨¡å¼
            st.warning("æœªæ‰¾åˆ°ç« èŠ‚æ ‡é¢˜ï¼Œå·²è‡ªåŠ¨åˆ‡æ¢åˆ°å¥å­æ¨¡å¼")
            return extract_knowledge_points(text, "å¥å­æ¨¡å¼", importance_threshold)
        
        sections = []
        
        # å°†æ–‡æœ¬æŒ‰ç« èŠ‚æ‹†åˆ†
        text_parts = []
        current_pos = 0
        
        for i, heading in enumerate(headings):
            # æŸ¥æ‰¾å½“å‰æ ‡é¢˜
            heading_pos = text.find(heading, current_pos)
            
            if heading_pos == -1:
                continue
                
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªæ ‡é¢˜ï¼Œå°†å‰ä¸€ä¸ªæ ‡é¢˜åˆ°å½“å‰æ ‡é¢˜ä¹‹é—´çš„å†…å®¹ä½œä¸ºå‰ä¸€ä¸ªæ ‡é¢˜çš„å†…å®¹
            if i > 0 and heading_pos > current_pos:
                text_parts.append(text[current_pos:heading_pos])
                
            current_pos = heading_pos + len(heading)
            
            # å¦‚æœæ˜¯æœ€åä¸€ä¸ªæ ‡é¢˜ï¼Œå°†å‰©ä½™å†…å®¹ä½œä¸ºæœ€åä¸€ä¸ªæ ‡é¢˜çš„å†…å®¹
            if i == len(headings) - 1:
                text_parts.append(text[current_pos:])
                
        # å¦‚æœæ‰¾åˆ°çš„ç« èŠ‚æ•°ä¸æ ‡é¢˜æ•°ä¸åŒ¹é…ï¼Œä½¿ç”¨ç®€å•çš„åˆ†å—æ–¹æ³•
        if len(text_parts) != len(headings):
            # ç®€å•åˆ†å—
            chunks = re.split(r'(ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+\s*[ç« èŠ‚]|Chapter\s+\d+|Section\s+\d+(?:\.\d+)*)', text)
            # é‡å»ºæ–‡æœ¬éƒ¨åˆ†
            text_parts = []
            for i in range(1, len(chunks), 2):
                if i+1 < len(chunks):
                    text_parts.append(chunks[i+1])
                
            # å¦‚æœè¿˜æ˜¯ä¸åŒ¹é…ï¼Œä½¿ç”¨å¹³å‡åˆ†å—
            if len(text_parts) != len(headings):
                text_parts = []
                chunk_size = len(text) // len(headings)
                for i in range(len(headings)):
                    start = i * chunk_size
                    end = start + chunk_size if i < len(headings) - 1 else len(text)
                    text_parts.append(text[start:end])
        
        # å¤„ç†æ¯ä¸ªç« èŠ‚
        for i, heading in enumerate(headings):
            if i < len(text_parts):
                section_text = text_parts[i]
                # ä¸ºæ¯ä¸ªç« èŠ‚æå–å…³é”®å¥å­
                sentences = extract_sentences(section_text)
                section_points = []
                
                for sentence in sentences:
                    sentence = sentence.strip()
                    if not sentence:
                        continue
                    
                    importance = score_importance(sentence, keywords, language=language)
                    if importance >= importance_threshold:
                        section_points.append({
                            "text": sentence,
                            "importance": importance,
                            "type": "sentence"
                        })
                
                # æŒ‰é‡è¦æ€§é™åºæ’åº
                section_points = sorted(section_points, key=lambda x: x["importance"], reverse=True)
                max_points = min(10, len(section_points))  # æ¯ç« æœ€å¤š10ä¸ªè¦ç‚¹
                
                sections.append({
                    "heading": heading,
                    "importance": 0.9,  # ç« èŠ‚æ ‡é¢˜é€šå¸¸å¾ˆé‡è¦
                    "type": "heading",
                    "points": section_points[:max_points]
                })
        
        return sections

def format_knowledge_points(knowledge_points, mode, output_format):
    """æ ¼å¼åŒ–çŸ¥è¯†ç‚¹ä¸ºæŒ‡å®šæ ¼å¼"""
    if mode == "ç« èŠ‚æ¨¡å¼":
        if output_format == "Markdown":
            content = "# PDFæ–‡æ¡£çŸ¥è¯†ç‚¹æç‚¼\n\n"
            
            for section in knowledge_points:
                content += f"## {section['heading']}\n\n"
                
                for point in section['points']:
                    content += f"- {point['text']}\n\n"
            
        else:  # çº¯æ–‡æœ¬
            content = "PDFæ–‡æ¡£çŸ¥è¯†ç‚¹æç‚¼\n\n"
            
            for section in knowledge_points:
                content += f"{section['heading']}\n"
                content += "=" * len(section['heading']) + "\n\n"
                
                for i, point in enumerate(section['points']):
                    content += f"{i+1}. {point['text']}\n\n"
    else:
        # å…³é”®è¯æ¨¡å¼æˆ–å¥å­æ¨¡å¼
        if output_format == "Markdown":
            content = "# PDFæ–‡æ¡£çŸ¥è¯†ç‚¹æç‚¼\n\n"
            
            for i, point in enumerate(knowledge_points):
                if point['type'] == "keyword":
                    content += f"- **{point['text']}**\n"
                else:
                    content += f"## çŸ¥è¯†ç‚¹ {i+1}\n\n{point['text']}\n\n"
        else:  # çº¯æ–‡æœ¬
            content = "PDFæ–‡æ¡£çŸ¥è¯†ç‚¹æç‚¼\n\n"
            
            for i, point in enumerate(knowledge_points):
                if point['type'] == "keyword":
                    content += f"* {point['text']}\n"
                else:
                    content += f"{i+1}. {point['text']}\n\n"
    
    return content

def show_pdf_extractor():
    """æ˜¾ç¤ºPDFçŸ¥è¯†ç‚¹æç‚¼ç•Œé¢"""
    st.markdown('<h1 class="main-header">PDFçŸ¥è¯†ç‚¹æç‚¼å·¥å…·</h1>', unsafe_allow_html=True)
    st.markdown('ä¸Šä¼ PDFæ–‡ä»¶ï¼Œè‡ªåŠ¨æå–é‡è¦çŸ¥è¯†ç‚¹ï¼Œå¸®åŠ©æ‚¨å¿«é€ŸæŒæ¡æ–‡æ¡£å†…å®¹ã€‚')
    
    # ä¾§è¾¹æ å‚æ•°è®¾ç½®
    with st.sidebar:
        st.header("å‚æ•°è®¾ç½®")
        
        importance = st.slider(
            "é‡è¦æ€§é˜ˆå€¼", 
            min_value=0.1, 
            max_value=0.9, 
            value=0.5, 
            step=0.1,
            help="è°ƒæ•´è¯¥å€¼æ§åˆ¶æå–çŸ¥è¯†ç‚¹çš„æ•°é‡ã€‚å€¼è¶Šå¤§ï¼Œæå–çš„çŸ¥è¯†ç‚¹è¶Šå°‘ä½†æ›´é‡è¦ã€‚"
        )
        
        mode = st.selectbox(
            "æå–æ¨¡å¼",
            ["è‡ªåŠ¨æ¨¡å¼", "å…³é”®è¯æ¨¡å¼", "å¥å­æ¨¡å¼", "ç« èŠ‚æ¨¡å¼"],
            help="è‡ªåŠ¨æ¨¡å¼ï¼šåˆ†ææ–‡æ¡£ç»“æ„é€‰æ‹©æœ€ä½³æå–æ–¹å¼\nå…³é”®è¯æ¨¡å¼ï¼šæå–é‡è¦æœ¯è¯­å’Œå…³é”®è¯\nå¥å­æ¨¡å¼ï¼šæå–é‡è¦å¥å­\nç« èŠ‚æ¨¡å¼ï¼šæŒ‰ç« èŠ‚ç»„ç»‡æå–"
        )
        
        output_format = st.selectbox(
            "è¾“å‡ºæ ¼å¼",
            ["Markdown", "çº¯æ–‡æœ¬"],
            help="Markdownï¼šæ ¼å¼åŒ–æ–‡æœ¬ï¼Œæ”¯æŒå±‚æ¬¡ç»“æ„\nçº¯æ–‡æœ¬ï¼šç®€å•æ–‡æœ¬æ ¼å¼"
        )
        
        # é«˜çº§é€‰é¡¹
        with st.expander("é«˜çº§é€‰é¡¹"):
            show_debug = st.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", value=False,
                                   help="æ˜¾ç¤ºåŸå§‹æå–æ–‡æœ¬å’Œå¤„ç†è¿‡ç¨‹")
        
        st.divider()
        
        st.write("**å…³äºæœ¬å·¥å…·**")
        st.write("æœ¬å·¥å…·å¸®åŠ©æ‚¨ä»PDFæ–‡æ¡£ä¸­æå–é‡è¦çŸ¥è¯†ç‚¹ï¼Œé€‚ç”¨äºæ–‡æœ¬å‹PDFã€‚")
        st.info("æ³¨æ„ï¼šæ‰«æç‰ˆPDFå¯èƒ½æ— æ³•æ­£å¸¸æå–æ–‡æœ¬ã€‚")
        st.write("æå–çš„çŸ¥è¯†ç‚¹æŒ‰é‡è¦æ€§æ’åºï¼Œå¯å¸®åŠ©æ‚¨å¿«é€ŸæŒæ¡æ–‡æ¡£æ ¸å¿ƒå†…å®¹ã€‚")
    
    # ä¸Šä¼ PDFæ–‡ä»¶
    uploaded_file = st.file_uploader("é€‰æ‹©PDFæ–‡ä»¶", type="pdf")
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        file_details = {
            "æ–‡ä»¶å": uploaded_file.name,
            "æ–‡ä»¶å¤§å°": f"{uploaded_file.size / 1024:.1f} KB"
        }
        st.write(file_details)
        
        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æå–çŸ¥è¯†ç‚¹"):
            with st.spinner("æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."):
                try:
                    # æå–æ–‡æœ¬
                    if show_debug:
                        text, results, errors = extract_text_from_pdf(uploaded_file, debug=True)
                    else:
                        text = extract_text_from_pdf(uploaded_file)
                    
                    # è°ƒè¯•ä¿¡æ¯
                    if show_debug:
                        st.subheader("è°ƒè¯•ä¿¡æ¯")
                        st.markdown("#### æå–æ–¹æ³•")
                        for method, result in results.items():
                            with st.expander(f"{method} æå–ç»“æœ"):
                                st.markdown(f'<div class="debug-info">{result[:2000]}{"..." if len(result) > 2000 else ""}</div>', unsafe_allow_html=True)
                        
                        if errors:
                            st.markdown("#### é”™è¯¯ä¿¡æ¯")
                            for error in errors:
                                st.markdown(f'<div class="error-message">{error}</div>', unsafe_allow_html=True)
                        
                        st.markdown("#### åŸå§‹æå–æ–‡æœ¬")
                        st.markdown(f'<div class="debug-info">{text[:3000]}{"..." if len(text) > 3000 else ""}</div>', unsafe_allow_html=True)
                    
                    # å¦‚æœæ–‡æœ¬æå–æˆåŠŸ
                    if text and not text.startswith("æ— æ³•æå–æ–‡æœ¬"):
                        # æå–çŸ¥è¯†ç‚¹
                        knowledge_points = extract_knowledge_points(text, mode, importance)
                        
                        if not knowledge_points or (mode != "ç« èŠ‚æ¨¡å¼" and len(knowledge_points) == 0) or \
                           (mode == "ç« èŠ‚æ¨¡å¼" and len(knowledge_points) == 0):
                            st.warning("æœªèƒ½æå–åˆ°è¶³å¤Ÿçš„çŸ¥è¯†ç‚¹ï¼Œæ­£åœ¨å°è¯•ä¸åŒçš„æå–æ¨¡å¼...")
                            # å°è¯•å…¶ä»–æ¨¡å¼
                            if mode != "å¥å­æ¨¡å¼":
                                knowledge_points = extract_knowledge_points(text, "å¥å­æ¨¡å¼", max(0.3, importance - 0.2))
                            
                            if not knowledge_points or len(knowledge_points) == 0:
                                knowledge_points = extract_knowledge_points(text, "å…³é”®è¯æ¨¡å¼", 0.3)
                                
                            if not knowledge_points or len(knowledge_points) == 0:
                                st.error("æ— æ³•ä»æ–‡æ¡£ä¸­æå–æœ‰æ•ˆçŸ¥è¯†ç‚¹ã€‚å¯èƒ½æ˜¯æ–‡æ¡£æ ¼å¼é—®é¢˜æˆ–æ–‡æœ¬å†…å®¹è¾ƒå°‘ã€‚")
                                st.stop()
                        
                        # æ ¼å¼åŒ–è¾“å‡º
                        result_content = format_knowledge_points(knowledge_points, mode, output_format)
                        
                        # åˆ›å»ºç»“æœåŒºåŸŸ
                        st.markdown('<h2 class="sub-header">æå–ç»“æœ</h2>', unsafe_allow_html=True)
                        
                        # æ˜¾ç¤ºçŸ¥è¯†ç‚¹
                        if mode == "ç« èŠ‚æ¨¡å¼":
                            for section in knowledge_points:
                                with st.expander(f"{section['heading']}"):
                                    for point in section['points']:
                                        st.markdown(f'<div class="knowledge-point">{point["text"]}</div>', unsafe_allow_html=True)
                        else:
                            # å…³é”®è¯æ¨¡å¼æˆ–å¥å­æ¨¡å¼
                            for point in knowledge_points[:20]:  # æœ€å¤šæ˜¾ç¤º20ä¸ªçŸ¥è¯†ç‚¹
                                if point['type'] == "keyword":
                                    st.markdown(f'<span class="highlight">{point["text"]}</span> ', unsafe_allow_html=True)
                                else:
                                    st.markdown(f'<div class="knowledge-point">{point["text"]}</div>', unsafe_allow_html=True)
                            
                            if len(knowledge_points) > 20:
                                st.info(f"å…±æå–äº† {len(knowledge_points)} ä¸ªçŸ¥è¯†ç‚¹ï¼Œä¸‹è½½æ–‡ä»¶å¯æŸ¥çœ‹å…¨éƒ¨å†…å®¹ã€‚")
                        
                        # ä¸‹è½½é“¾æ¥
                        st.markdown("### ä¸‹è½½ç»“æœ")
                        filename = f"{uploaded_file.name.split('.')[0]}_çŸ¥è¯†ç‚¹.{'md' if output_format == 'Markdown' else 'txt'}"
                        download_link = create_downloadable_link(result_content, filename, "ç‚¹å‡»ä¸‹è½½çŸ¥è¯†ç‚¹æå–ç»“æœ")
                        st.markdown(download_link, unsafe_allow_html=True)
                        
                        # ç»Ÿè®¡ä¿¡æ¯
                        if mode == "ç« èŠ‚æ¨¡å¼":
                            total_points = sum(len(s['points']) for s in knowledge_points)
                            st.sidebar.success(f"æˆåŠŸæå–äº† {len(knowledge_points)} ä¸ªç« èŠ‚å’Œ {total_points} ä¸ªçŸ¥è¯†ç‚¹")
                        else:
                            st.sidebar.success(f"æˆåŠŸæå–äº† {len(knowledge_points)} ä¸ªçŸ¥è¯†ç‚¹")
                    
                    else:
                        # æ–‡æœ¬æå–å¤±è´¥
                        st.error("æ— æ³•ä»PDFä¸­æå–æœ‰æ•ˆæ–‡æœ¬ã€‚è¿™å¯èƒ½æ˜¯ä¸€ä¸ªæ‰«æç‰ˆPDFæˆ–å—ä¿æŠ¤çš„æ–‡æ¡£ã€‚")
                        st.info("ç›®å‰ç‰ˆæœ¬ä¸æ”¯æŒæ‰«æç‰ˆPDFçš„å¤„ç†ã€‚è¯·å°è¯•ä½¿ç”¨æ–‡æœ¬å‹PDFæ–‡ä»¶ã€‚")
                        
                        # æ˜¾ç¤ºæå–çš„éƒ¨åˆ†æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
                        if text and show_debug:
                            st.markdown("#### æå–çš„éƒ¨åˆ†æ–‡æœ¬")
                            st.markdown(f'<div class="debug-info">{text[:1000]}{"..." if len(text) > 1000 else ""}</div>', unsafe_allow_html=True)
                    
                except Exception as e:
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                    st.info("æç¤ºï¼šå¦‚æœæ˜¯PDFæ ¼å¼é—®é¢˜ï¼Œè¯·å°è¯•ä½¿ç”¨å…¶ä»–PDFæ–‡ä»¶ã€‚")
                    import traceback
                    if show_debug:
                        st.markdown("#### é”™è¯¯è¯¦æƒ…")
                        st.markdown(f'<div class="error-message">{traceback.format_exc()}</div>', unsafe_allow_html=True)
    else:
        # æœªä¸Šä¼ æ–‡ä»¶æ—¶æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.info("è¯·ä¸Šä¼ PDFæ–‡ä»¶ä»¥å¼€å§‹æå–çŸ¥è¯†ç‚¹")
        
        with st.expander("ä½¿ç”¨æŒ‡å—"):
            st.markdown("""
            ### åŸºæœ¬ä½¿ç”¨æµç¨‹
            
           ### åŸºæœ¬ä½¿ç”¨æµç¨‹
            
            1. åœ¨å·¦ä¾§ä¸Šä¼ ä¸€ä¸ªPDFæ–‡ä»¶ï¼ˆæ”¯æŒä¸­è‹±æ–‡æ–‡æ¡£ï¼‰
            2. æ ¹æ®éœ€è¦è°ƒæ•´å‚æ•°ï¼š
               - **é‡è¦æ€§é˜ˆå€¼**ï¼šæ§åˆ¶æå–çš„çŸ¥è¯†ç‚¹æ•°é‡å’Œè´¨é‡
               - **æå–æ¨¡å¼**ï¼šé€‰æ‹©é€‚åˆæ‚¨æ–‡æ¡£çš„æå–æ–¹å¼
               - **è¾“å‡ºæ ¼å¼**ï¼šé€‰æ‹©ç»“æœçš„æ ¼å¼åŒ–æ–¹å¼
            3. åœ¨é«˜çº§é€‰é¡¹ä¸­ï¼Œå¯ä»¥å¯ç”¨è°ƒè¯•ä¿¡æ¯æŸ¥çœ‹è¯¦ç»†å¤„ç†è¿‡ç¨‹
            4. ç‚¹å‡»"å¼€å§‹æå–çŸ¥è¯†ç‚¹"æŒ‰é’®
            5. æŸ¥çœ‹æå–ç»“æœå¹¶ä¸‹è½½
            
            ### æå–æ¨¡å¼è¯´æ˜
            
            - **è‡ªåŠ¨æ¨¡å¼**ï¼šç³»ç»Ÿåˆ†ææ–‡æ¡£ç»“æ„ï¼Œé€‰æ‹©æœ€åˆé€‚çš„æå–æ–¹å¼
            - **å…³é”®è¯æ¨¡å¼**ï¼šæå–æ–‡æ¡£ä¸­çš„é‡è¦æœ¯è¯­å’Œå…³é”®è¯
            - **å¥å­æ¨¡å¼**ï¼šæå–åŒ…å«é‡è¦ä¿¡æ¯çš„å®Œæ•´å¥å­
            - **ç« èŠ‚æ¨¡å¼**ï¼šæŒ‰æ–‡æ¡£ç« èŠ‚ç»“æ„ç»„ç»‡æå–çš„çŸ¥è¯†ç‚¹
            
            ### é‡è¦æ€§é˜ˆå€¼
            
            - **0.1-0.3**ï¼šæå–æ›´å¤šçŸ¥è¯†ç‚¹ï¼ŒåŒ…æ‹¬æ¬¡è¦å†…å®¹
            - **0.4-0.6**ï¼šå¹³è¡¡æ•°é‡å’Œè´¨é‡
            - **0.7-0.9**ï¼šä»…æå–æœ€é‡è¦çš„çŸ¥è¯†ç‚¹
            
            ### æ”¯æŒçš„PDFç±»å‹
            
            - æ–‡æœ¬å‹PDFï¼ˆå¦‚ä»Wordå¯¼å‡ºçš„PDFï¼‰
            - åŒ…å«å¯é€‰æ‹©æ–‡æœ¬çš„PDF
            - æ³¨æ„ï¼šå½“å‰ç‰ˆæœ¬ä¸æ”¯æŒæ‰«æç‰ˆPDF
            """)

        with st.expander("ä½¿ç”¨æç¤º"):
            st.markdown("""
            ### é€‚åˆå¤„ç†çš„æ–‡æ¡£
            
            âœ… å­¦æœ¯è®ºæ–‡å’Œç ”ç©¶æŠ¥å‘Š  
            âœ… æŠ€æœ¯æ–‡æ¡£å’Œä½¿ç”¨æ‰‹å†Œ  
            âœ… æ•™æå’Œå­¦ä¹ èµ„æ–™  
            âœ… ä¼ä¸šæŠ¥å‘Šå’Œæ”¿ç­–æ–‡ä»¶  
            âœ… ç”µå­ä¹¦å’Œæ–‡ç« ï¼ˆæ–‡æœ¬å‹ï¼‰  
            
            ### ä¸é€‚åˆå¤„ç†çš„æ–‡æ¡£
            
            âŒ æ‰«æç‰ˆPDFï¼ˆæ— æ–‡æœ¬å±‚ï¼‰  
            âŒ ä¸»è¦ç”±å›¾è¡¨ç»„æˆçš„æ–‡æ¡£  
            âŒ å¯†ç ä¿æŠ¤æˆ–åŠ å¯†PDF  
            âŒ æ ¼å¼éå¸¸å¤æ‚çš„PDF  
            
            ### æé«˜æå–è´¨é‡çš„æŠ€å·§
            
            1. ç¡®ä¿PDFæ–‡ä»¶æ¸…æ™°ï¼Œæ–‡æœ¬å¯é€‰æ‹©
            2. å¯¹äºå†…å®¹ä¸°å¯Œçš„æ–‡æ¡£ï¼Œé€‚å½“é™ä½é‡è¦æ€§é˜ˆå€¼
            3. æ ¹æ®æ–‡æ¡£ç»“æ„é€‰æ‹©åˆé€‚çš„æå–æ¨¡å¼
            4. ä½¿ç”¨"è‡ªåŠ¨æ¨¡å¼"è®©ç³»ç»Ÿè‡ªè¡Œåˆ¤æ–­æœ€ä½³æå–æ–¹å¼
            """)

def show_ppt_generator():
    """æ˜¾ç¤ºPPTç”Ÿæˆå™¨ç•Œé¢"""
    st.markdown('<h1 class="main-header">PDFç”ŸæˆPPTå·¥å…·</h1>', unsafe_allow_html=True)
    st.markdown('ä¸Šä¼ PDFæ–‡ä»¶ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºPPTæ¼”ç¤ºæ–‡ç¨¿ã€‚')
    
    st.info("è¯¥åŠŸèƒ½å°†ä½¿ç”¨PDFæå–çš„çŸ¥è¯†ç‚¹è‡ªåŠ¨åˆ›å»ºPowerPointæ¼”ç¤ºæ–‡ç¨¿ã€‚")
    
    # ä¾§è¾¹æ å‚æ•°
    with st.sidebar:
        st.header("PPTè®¾ç½®")
        
        ppt_theme = st.selectbox(
            "PPTä¸»é¢˜",
            ["ç®€çº¦è“", "å•†åŠ¡ç°", "å­¦æœ¯ç»¿", "é²œæ˜çº¢", "æš—é»‘æ¨¡å¼"],
            help="é€‰æ‹©PPTçš„è§†è§‰ä¸»é¢˜"
        )
        
        slide_density = st.slider(
            "å¹»ç¯ç‰‡å†…å®¹å¯†åº¦", 
            min_value=1, 
            max_value=5, 
            value=3,
            help="1=æ¯å¼ å¹»ç¯ç‰‡å†…å®¹è¾ƒå°‘ï¼Œ5=æ¯å¼ å¹»ç¯ç‰‡å†…å®¹è¾ƒå¤š"
        )
        
        include_toc = st.checkbox("åŒ…å«ç›®å½•é¡µ", value=True)
        include_cover = st.checkbox("åŒ…å«å°é¢", value=True)
        
    # ä¸Šä¼ PDFæ–‡ä»¶
    uploaded_file = st.file_uploader("é€‰æ‹©PDFæ–‡ä»¶", type="pdf")
    
    if uploaded_file is not None:
        file_details = {
            "æ–‡ä»¶å": uploaded_file.name,
            "æ–‡ä»¶å¤§å°": f"{uploaded_file.size / 1024:.1f} KB"
        }
        st.write(file_details)
        
        # å°é¢è®¾ç½®ï¼ˆå¯é€‰ï¼‰
        if include_cover:
            with st.expander("å°é¢è®¾ç½®"):
                title = st.text_input("æ¼”ç¤ºæ ‡é¢˜", value=uploaded_file.name.split('.')[0])
                subtitle = st.text_input("æ¼”ç¤ºå‰¯æ ‡é¢˜", value="è‡ªåŠ¨ç”Ÿæˆçš„æ¼”ç¤ºæ–‡ç¨¿")
                author = st.text_input("ä½œè€…", value="")
                date = st.date_input("æ—¥æœŸ")
        
        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹ç”ŸæˆPPT"):
            with st.spinner("æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."):
                try:
                    # é¦–å…ˆæå–æ–‡æœ¬å’ŒçŸ¥è¯†ç‚¹
                    text = extract_text_from_pdf(uploaded_file)
                    
                    if text and not text.startswith("æ— æ³•æå–æ–‡æœ¬"):
                        # æå–çŸ¥è¯†ç‚¹ï¼ˆä½¿ç”¨ç« èŠ‚æ¨¡å¼ä»¥è·å¾—æ›´å¥½çš„ç»“æ„ï¼‰
                        knowledge_points = extract_knowledge_points(text, "ç« èŠ‚æ¨¡å¼", 0.4)
                        
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç« èŠ‚ï¼Œå°è¯•å¥å­æ¨¡å¼
                        if not knowledge_points or len(knowledge_points) == 0:
                            knowledge_points = extract_knowledge_points(text, "å¥å­æ¨¡å¼", 0.4)
                        
                        # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                        st.success("å·²æˆåŠŸåˆ†ææ–‡æ¡£å†…å®¹ï¼")
                        
                        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨PPTç”Ÿæˆæ¨¡å—
                        # ç”±äºæˆ‘ä»¬å°šæœªé›†æˆå®é™…çš„PPTç”ŸæˆåŠŸèƒ½ï¼Œæ˜¾ç¤ºä¸€ä¸ªæ¨¡æ‹Ÿç•Œé¢
                        st.markdown("### ç”Ÿæˆçš„PPTé¢„è§ˆ")
                        
                        # æ¨¡æ‹ŸPPTé¢„è§ˆ
                        cols = st.columns(3)
                        with cols[0]:
                            st.markdown("""
                            <div style="border:1px solid #ddd; padding:10px; text-align:center;">
                                <h4>å°é¢</h4>
                                <p>æ¼”ç¤ºæ ‡é¢˜</p>
                                <p>å‰¯æ ‡é¢˜</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        with cols[1]:
                            st.markdown("""
                            <div style="border:1px solid #ddd; padding:10px; text-align:center;">
                                <h4>ç›®å½•</h4>
                                <p>ä¸»è¦ç« èŠ‚1</p>
                                <p>ä¸»è¦ç« èŠ‚2</p>
                                <p>...</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        with cols[2]:
                            st.markdown("""
                            <div style="border:1px solid #ddd; padding:10px; text-align:center;">
                                <h4>å†…å®¹é¡µ</h4>
                                <p>ä¸»è¦çŸ¥è¯†ç‚¹</p>
                                <p>æ”¯æŒè¦ç‚¹</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        # ä¸‹è½½æŒ‰é’®ï¼ˆæ¨¡æ‹Ÿï¼‰
                        st.info("æç¤ºï¼šPPTç”ŸæˆåŠŸèƒ½ä»åœ¨å¼€å‘ä¸­ï¼Œç›®å‰ä»…æä¾›é¢„è§ˆã€‚")
                        if st.button("æ¨¡æ‹Ÿä¸‹è½½PPT"):
                            st.success("åœ¨çœŸå®åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæä¾›ä¸€ä¸ªPPTæ–‡ä»¶ä¸‹è½½é“¾æ¥ã€‚")
                    else:
                        st.error("æ— æ³•ä»PDFä¸­æå–æœ‰æ•ˆæ–‡æœ¬ã€‚è¯·å°è¯•ä½¿ç”¨æ–‡æœ¬å‹PDFæ–‡ä»¶ã€‚")
                    
                except Exception as e:
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                    st.info("æç¤ºï¼šå¦‚æœæ˜¯PDFæ ¼å¼é—®é¢˜ï¼Œè¯·å°è¯•ä½¿ç”¨å…¶ä»–PDFæ–‡ä»¶ã€‚")
    else:
        st.info("è¯·ä¸Šä¼ PDFæ–‡ä»¶ä»¥ç”ŸæˆPPT")
        
        with st.expander("åŠŸèƒ½è¯´æ˜"):
            st.markdown("""
            ### PDFè½¬PPTåŠŸèƒ½
            
            æœ¬åŠŸèƒ½ä¼šè‡ªåŠ¨åˆ†ææ‚¨çš„PDFæ–‡æ¡£å†…å®¹ï¼Œæå–é‡è¦çŸ¥è¯†ç‚¹ï¼Œå¹¶ç”Ÿæˆç»“æ„åŒ–çš„PPTæ¼”ç¤ºæ–‡ç¨¿ã€‚
            
            **ä¸»è¦åŠŸèƒ½**ï¼š
            - è‡ªåŠ¨æå–æ–‡æ¡£ç»“æ„å’Œå†…å®¹
            - æ ¹æ®æ–‡æ¡£ç»“æ„åˆ›å»ºå¹»ç¯ç‰‡
            - æ”¯æŒè‡ªå®šä¹‰PPTä¸»é¢˜å’Œé£æ ¼
            - å¯è°ƒæ•´å†…å®¹å¯†åº¦å’Œå±•ç¤ºæ–¹å¼
            
            **ä½¿ç”¨å»ºè®®**ï¼š
            - ä¸Šä¼ ç»“æ„æ¸…æ™°çš„æ–‡æœ¬å‹PDF
            - ä¸ºè·å¾—æœ€ä½³æ•ˆæœï¼Œé€‰æ‹©åŒ…å«æ¸…æ™°æ ‡é¢˜å’Œå°æ ‡é¢˜çš„æ–‡æ¡£
            - è°ƒæ•´å†…å®¹å¯†åº¦ä»¥æ§åˆ¶æ¯å¼ å¹»ç¯ç‰‡çš„ä¿¡æ¯é‡
            """)

def show_animation_generator():
    """æ˜¾ç¤ºåŠ¨ç”»ç”Ÿæˆå™¨ç•Œé¢"""
    st.markdown('<h1 class="main-header">çŸ¥è¯†ç‚¹åŠ¨ç”»ç”Ÿæˆå·¥å…·</h1>', unsafe_allow_html=True)
    st.markdown('ä¸Šä¼ PDFæ–‡ä»¶æˆ–è¾“å…¥æ–‡æœ¬ï¼Œç”ŸæˆçŸ¥è¯†ç‚¹è®²è§£åŠ¨ç”»ã€‚')
    
    st.info("è¯¥åŠŸèƒ½å¯å°†PDFæ–‡æ¡£æˆ–æ–‡æœ¬å†…å®¹è½¬æ¢ä¸ºç”ŸåŠ¨çš„åŠ¨ç”»è®²è§£è§†é¢‘ã€‚")
    
    # ä¾§è¾¹æ å‚æ•°
    with st.sidebar:
        st.header("åŠ¨ç”»è®¾ç½®")
        
        animation_style = st.selectbox(
            "åŠ¨ç”»é£æ ¼",
            ["ç®€çº¦æ•™å­¦", "ç”ŸåŠ¨æ´»æ³¼", "ä¸“ä¸šå•†åŠ¡", "ç§‘æŠ€æ„Ÿ"],
            help="é€‰æ‹©åŠ¨ç”»çš„è§†è§‰é£æ ¼"
        )
        
        voice_type = st.selectbox(
            "é…éŸ³é£æ ¼",
            ["æˆç†Ÿç”·å£°", "äº²å’Œå¥³å£°", "æ´»åŠ›é’å¹´", "æ— é…éŸ³"],
            help="é€‰æ‹©è®²è§£éŸ³é¢‘çš„é…éŸ³ç±»å‹"
        )
        
        animation_length = st.slider(
            "åŠ¨ç”»æ—¶é•¿ç›®æ ‡(åˆ†é’Ÿ)", 
            min_value=1,
            max_value=10, 
            value=3,
            help="è®¾ç½®ç”Ÿæˆçš„åŠ¨ç”»å¤§è‡´æ—¶é•¿"
        )
        
        include_background_music = st.checkbox("æ·»åŠ èƒŒæ™¯éŸ³ä¹", value=True)
    
    # å†…å®¹è¾“å…¥é€‰é¡¹
    input_method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["ä¸Šä¼ PDF", "ç›´æ¥è¾“å…¥æ–‡æœ¬"])
    
    if input_method == "ä¸Šä¼ PDF":
        uploaded_file = st.file_uploader("é€‰æ‹©PDFæ–‡ä»¶", type="pdf")
        
        if uploaded_file is not None:
            file_details = {
                "æ–‡ä»¶å": uploaded_file.name,
                "æ–‡ä»¶å¤§å°": f"{uploaded_file.size / 1024:.1f} KB"
            }
            st.write(file_details)
            
            # å¤„ç†æŒ‰é’®
            if st.button("å¼€å§‹ç”ŸæˆåŠ¨ç”»"):
                with st.spinner("æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."):
                    try:
                        # é¦–å…ˆæå–æ–‡æœ¬å’ŒçŸ¥è¯†ç‚¹
                        text = extract_text_from_pdf(uploaded_file)
                        
                        if text and not text.startswith("æ— æ³•æå–æ–‡æœ¬"):
                            # æå–çŸ¥è¯†ç‚¹
                            knowledge_points = extract_knowledge_points(text, "å¥å­æ¨¡å¼", 0.4)
                            
                            # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                            st.success("å·²æˆåŠŸåˆ†ææ–‡æ¡£å†…å®¹ï¼")
                            
                            # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨åŠ¨ç”»ç”Ÿæˆæ¨¡å—
                            # ç”±äºæˆ‘ä»¬å°šæœªé›†æˆå®é™…çš„åŠ¨ç”»ç”ŸæˆåŠŸèƒ½ï¼Œæ˜¾ç¤ºä¸€ä¸ªæ¨¡æ‹Ÿç•Œé¢
                            st.markdown("### åŠ¨ç”»ç”Ÿæˆé¢„è§ˆ")
                            
                            # æ¨¡æ‹ŸåŠ¨ç”»é¢„è§ˆ
                            st.markdown("""
                            <div style="background:#f0f0f0; padding:20px; border-radius:5px; text-align:center;">
                                <h4>åŠ¨ç”»é¢„è§ˆåŒºåŸŸ</h4>
                                <p style="color:#555;">å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæ˜¾ç¤ºåŠ¨ç”»é¢„è§ˆæˆ–ç”Ÿæˆè¿›åº¦</p>
                                <div style="background:#ddd; height:240px; display:flex; align-items:center; justify-content:center;">
                                    <p>åŠ¨ç”»é¢„è§ˆç”»é¢</p>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # ä¸‹è½½æŒ‰é’®ï¼ˆæ¨¡æ‹Ÿï¼‰
                            st.info("æç¤ºï¼šåŠ¨ç”»ç”ŸæˆåŠŸèƒ½ä»åœ¨å¼€å‘ä¸­ï¼Œç›®å‰ä»…æä¾›ç•Œé¢é¢„è§ˆã€‚")
                            if st.button("æ¨¡æ‹Ÿä¸‹è½½åŠ¨ç”»"):
                                st.success("åœ¨çœŸå®åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæä¾›ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ä¸‹è½½é“¾æ¥ã€‚")
                        else:
                            st.error("æ— æ³•ä»PDFä¸­æå–æœ‰æ•ˆæ–‡æœ¬ã€‚è¯·å°è¯•ä½¿ç”¨æ–‡æœ¬å‹PDFæ–‡ä»¶ã€‚")
                        
                    except Exception as e:
                        st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                        st.info("æç¤ºï¼šå¦‚æœæ˜¯PDFæ ¼å¼é—®é¢˜ï¼Œè¯·å°è¯•ä½¿ç”¨å…¶ä»–PDFæ–‡ä»¶ã€‚")
        else:
            st.info("è¯·ä¸Šä¼ PDFæ–‡ä»¶ä»¥ç”ŸæˆåŠ¨ç”»")
    
    else:  # ç›´æ¥è¾“å…¥æ–‡æœ¬
        input_text = st.text_area("è¾“å…¥è¦è½¬æ¢ä¸ºåŠ¨ç”»çš„æ–‡æœ¬å†…å®¹", height=200)
        
        if st.button("å¼€å§‹ç”ŸæˆåŠ¨ç”»") and input_text:
            with st.spinner("æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."):
                try:
                    # ä½¿ç”¨æ–‡æœ¬è¿›è¡ŒçŸ¥è¯†ç‚¹æå–
                    if len(input_text.strip()) > 10:
                        # æå–çŸ¥è¯†ç‚¹
                        knowledge_points = extract_knowledge_points(input_text, "å¥å­æ¨¡å¼", 0.4)
                        
                        # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                        st.success("å·²æˆåŠŸåˆ†ææ–‡æœ¬å†…å®¹ï¼")
                        
                        # æ˜¾ç¤ºæ¨¡æ‹Ÿç•Œé¢ï¼ˆä¸PDFéƒ¨åˆ†ç›¸åŒï¼‰
                        st.markdown("### åŠ¨ç”»ç”Ÿæˆé¢„è§ˆ")
                        
                        # æ¨¡æ‹ŸåŠ¨ç”»é¢„è§ˆ
                        st.markdown("""
                        <div style="background:#f0f0f0; padding:20px; border-radius:5px; text-align:center;">
                            <h4>åŠ¨ç”»é¢„è§ˆåŒºåŸŸ</h4>
                            <p style="color:#555;">å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæ˜¾ç¤ºåŠ¨ç”»é¢„è§ˆæˆ–ç”Ÿæˆè¿›åº¦</p>
                            <div style="background:#ddd; height:240px; display:flex; align-items:center; justify-content:center;">
                                <p>åŠ¨ç”»é¢„è§ˆç”»é¢</p>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # ä¸‹è½½æŒ‰é’®ï¼ˆæ¨¡æ‹Ÿï¼‰
                        st.info("æç¤ºï¼šåŠ¨ç”»ç”ŸæˆåŠŸèƒ½ä»åœ¨å¼€å‘ä¸­ï¼Œç›®å‰ä»…æä¾›ç•Œé¢é¢„è§ˆã€‚")
                        if st.button("æ¨¡æ‹Ÿä¸‹è½½åŠ¨ç”»"):
                            st.success("åœ¨çœŸå®åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæä¾›ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ä¸‹è½½é“¾æ¥ã€‚")
                    else:
                        st.error("è¾“å…¥æ–‡æœ¬å¤ªçŸ­ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ„ä¹‰çš„åŠ¨ç”»ã€‚")
                
                except Exception as e:
                    st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        
    with st.expander("åŠŸèƒ½è¯´æ˜"):
        st.markdown("""
        ### çŸ¥è¯†ç‚¹åŠ¨ç”»ç”ŸæˆåŠŸèƒ½
        
        æœ¬åŠŸèƒ½å¯ä»¥å°†PDFæ–‡æ¡£æˆ–æ–‡æœ¬è½¬æ¢ä¸ºç”ŸåŠ¨çš„çŸ¥è¯†ç‚¹è®²è§£åŠ¨ç”»ã€‚
        
        **ä¸»è¦åŠŸèƒ½**ï¼š
        - è‡ªåŠ¨æå–æ–‡æ¡£ä¸­çš„å…³é”®çŸ¥è¯†ç‚¹
        - å°†çŸ¥è¯†ç‚¹è½¬æ¢ä¸ºåŠ¨ç”»å½¢å¼çš„è®²è§£å†…å®¹
        - æ”¯æŒè‡ªå®šä¹‰åŠ¨ç”»é£æ ¼å’Œé…éŸ³
        - å¯é€‰æ·»åŠ èƒŒæ™¯éŸ³ä¹
        
        **ä½¿ç”¨å»ºè®®**ï¼š
        - ä¸Šä¼ å†…å®¹æ¸…æ™°çš„æ–‡æœ¬å‹PDFæˆ–ç›´æ¥è¾“å…¥æ–‡æœ¬
        - å†…å®¹æœ€å¥½ä»¥çŸ¥è¯†ç‚¹è®²è§£ç±»å‹ä¸ºä¸»
        - ä¸ºè·å¾—æœ€ä½³æ•ˆæœï¼Œæ§åˆ¶è¾“å…¥å†…å®¹çš„é•¿åº¦å’Œå¤æ‚åº¦
        """)

# ä¸»å‡½æ•°
def main():
    # åœ¨ä¾§è¾¹æ æ·»åŠ åŠŸèƒ½é€‰æ‹©
    with st.sidebar:
        st.title("PDFå¤šåŠŸèƒ½å·¥å…·")
        app_mode = st.radio(
            "é€‰æ‹©åŠŸèƒ½",
            ["PDFçŸ¥è¯†ç‚¹æç‚¼", "ç”ŸæˆPPT", "ç”ŸæˆåŠ¨ç”»"],
            help="é€‰æ‹©æ‚¨æƒ³è¦ä½¿ç”¨çš„åŠŸèƒ½"
        )
        st.divider()
    
    # æ ¹æ®é€‰æ‹©åŠ è½½ä¸åŒåŠŸèƒ½
    if app_mode == "PDFçŸ¥è¯†ç‚¹æç‚¼":
        show_pdf_extractor()
    elif app_mode == "ç”ŸæˆPPT":
        show_ppt_generator()
    elif app_mode == "ç”ŸæˆåŠ¨ç”»":
        show_animation_generator()

    # æ·»åŠ é¡µè„š
    st.markdown("""
    ---
    <p style="text-align: center; color: gray; font-size: 0.8em;">
    PDFå¤šåŠŸèƒ½å·¥å…· | ç‰ˆæœ¬ 1.0 | Â© 2025
    </p>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
